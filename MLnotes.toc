\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {british}{}
\defcounter {refsection}{0}\relax 
\vspace {-\cftbeforepartskip }
\babel@toc {british}{}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {1}{Introduction}}{3}{chapter.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.1}{Intro to AI}}{3}{section.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.1.1}{On governance/policy}}{4}{subsection.1.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.1.2}{ML}}{4}{subsection.1.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.1.2.1}{What is ML -- the schools of thought}}{4}{subsubsection.1.1.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.1.2.2}{What means training ?}}{6}{subsubsection.1.1.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.1.2.3}{Intriccacies with}}{7}{subsubsection.1.1.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.1.3}{Big Data}}{7}{subsection.1.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {1.2}{Math basics}}{7}{section.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.2.1}{Different possible types of learning}}{7}{subsection.1.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.2.1.1}{Supervised learning}}{7}{subsubsection.1.2.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.2.1.2}{Unsupervised learning}}{8}{subsubsection.1.2.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.2.1.3}{Reinforcement learning}}{9}{subsubsection.1.2.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.2.1.4}{On the learning process}}{9}{subsubsection.1.2.1.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.2.2}{Cost function}}{11}{subsection.1.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {1.2.2.1}{An example: The gradient descent algorithm}}{12}{subsubsection.1.2.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {1.2.3}{Data processing}}{13}{subsection.1.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {2}{Supervised learning}}{15}{chapter.2}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.1}{More formal introduction into the idea of Machine Learning}}{15}{section.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1.1}{Problem set-up and recipe}}{15}{subsection.2.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.1.1}{Ingredients}}{15}{subsubsection.2.1.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.1.2}{Recipe}}{16}{subsubsection.2.1.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.1.2}{Performance evaluation}}{16}{subsection.2.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.2.1}{Ingredients for performance evaluation}}{16}{subsubsection.2.1.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.2.2}{Another mathematical measure for performance evaluation}}{18}{subsubsection.2.1.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.2.3}{How to effectively do the performance evaluation}}{18}{subsubsection.2.1.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.1.2.4}{Where do the insights about how to do best practices come from ?}}{20}{subsubsection.2.1.2.4}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.2}{Statistics}}{21}{section.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.1}{Difference between estimation and prediction}}{21}{subsection.2.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.1.1}{Contrasting the two}}{21}{subsubsection.2.2.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.2}{Mathematical motivation to presented key ideas}}{22}{subsection.2.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.2.1}{Bias-Variance Decomposition for one Classifier}}{22}{subsubsection.2.2.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.2.2}{Bias-Variance Decomposition for Ensembles}}{24}{subsubsection.2.2.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.3}{Mathematical set-up of every problem ever}}{26}{subsection.2.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.3.1}{Set-up of the notation}}{26}{subsubsection.2.2.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.3.2}{Set-up of the problem}}{27}{subsubsection.2.2.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.3.3}{On statistical language}}{27}{subsubsection.2.2.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.2.4}{Language of optimization problems}}{28}{subsection.2.2.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.2.4.1}{Convexity}}{28}{subsubsection.2.2.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.3}{Overview of Bayesian Inference}}{28}{section.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.1}{Language}}{28}{subsection.2.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.1.1}{Connecting statistics and bayesian framework}}{30}{subsubsection.2.3.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.2}{Calculations}}{30}{subsection.2.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.3}{Estimation}}{31}{subsection.2.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.3.1}{Maximum Likelihood estimation}}{31}{subsubsection.2.3.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.3.2}{Maximum-a-Posteriori estimation}}{32}{subsubsection.2.3.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.3.3}{Out-of-Bag estimators}}{32}{subsubsection.2.3.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.3.4}{Bayesian view on regularization}}{32}{subsection.2.3.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.3.4.1}{MAP estimator in the context of regularization}}{33}{subsubsection.2.3.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.4}{Information theory}}{33}{section.2.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.4.1}{Relative Entropy or Kullback-Leibler divergence}}{33}{subsection.2.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.5}{Mathematical tools}}{34}{section.2.5}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.1}{Sampling methods}}{34}{subsection.2.5.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.5.1.1}{Empirical Bootstrapping}}{34}{subsubsection.2.5.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.5.2}{Algorithms}}{35}{subsection.2.5.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.5.2.1}{Decision Trees}}{35}{subsubsection.2.5.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.6}{Gradient descent}}{37}{section.2.6}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.6.1}{Simple gradient descent}}{37}{subsection.2.6.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.6.2}{Modified gradient descent}}{38}{subsection.2.6.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.6.2.1}{Stochastic gradient descent (SGD) with mini-batches}}{38}{subsubsection.2.6.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.6.2.2}{Algorithm gradient descent with momentum}}{38}{subsubsection.2.6.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.6.2.3}{Methods that use the second moment of the gradient}}{38}{subsubsection.2.6.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.6.3}{Practical tips for using GD}}{40}{subsection.2.6.3}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.7}{Linear regression}}{40}{section.2.7}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.1}{Least-square regressions -frequentist}}{40}{subsection.2.7.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.2}{Regularized Least-square regressions-frequentist}}{42}{subsection.2.7.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2.1}{Ridge-Regression}}{43}{subsubsection.2.7.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2.2}{LASSO and Sparse Regression}}{44}{subsubsection.2.7.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2.3}{A note on LASSO and Ridge}}{45}{subsubsection.2.7.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2.4}{Another note being a general comment on regularization}}{45}{subsubsection.2.7.2.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.2.5}{A general perspective on regularizers}}{46}{subsubsection.2.7.2.5}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.3}{Bayesian formulation of linear regression}}{46}{subsection.2.7.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.7.3.1}{Regularization }}{46}{subsubsection.2.7.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.7.4}{Outlook from linear regression}}{47}{subsection.2.7.4}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.8}{Logistic Regression}}{47}{section.2.8}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.1}{Mathematical set-up}}{47}{subsection.2.8.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.1.1}{Binary classification}}{47}{subsubsection.2.8.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.1.2}{Multi-class classification}}{47}{subsubsection.2.8.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.2}{Classifiers}}{48}{subsection.2.8.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.2.1}{On threshold function functions}}{48}{subsubsection.2.8.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.3}{Perceptron Learning Algorithm (PLA)}}{48}{subsection.2.8.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.3.1}{The algorithm}}{49}{subsubsection.2.8.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.4}{Definition of logistic regression - Bayesian}}{50}{subsection.2.8.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.4.1}{On the 2d Ising example}}{51}{subsubsection.2.8.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.8.4.2}{SUSY }}{51}{subsubsection.2.8.4.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.8.5}{SoftMax regression}}{51}{subsection.2.8.5}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.9}{Ensemble Methods - On combining models}}{52}{section.2.9}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.9.1}{Introduction}}{52}{subsection.2.9.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.9.1.1}{Motivation}}{52}{subsubsection.2.9.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.9.1.2}{Benefits of Ensemble Methods before diving in}}{53}{subsubsection.2.9.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.9.2}{Aggregate predictor methods - Bagging and Boosting}}{54}{subsection.2.9.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.9.2.1}{Bagging}}{54}{subsubsection.2.9.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.9.2.2}{Boosting}}{56}{subsubsection.2.9.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.9.3}{Random Forests}}{57}{subsection.2.9.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.9.4}{Gradient Boosted Trees and XGBoost}}{58}{subsection.2.9.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.9.4.1}{XGBoost}}{58}{subsubsection.2.9.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.10}{An Introduction to Feed-Forward Deep Neural Networks (DNNS)}}{61}{section.2.10}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.1}{Neural Network Basics}}{61}{subsection.2.10.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.1.1}{The basic building block: neurons}}{61}{subsubsection.2.10.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.1.2}{Layering neurons to build deep networks: network architecture}}{63}{subsubsection.2.10.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.1.3}{Further on network architecture: How many layers is adequate for a problem ?}}{66}{subsubsection.2.10.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.2}{Training deep networks}}{67}{subsection.2.10.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.3}{The Backpropagation algorithm}}{68}{subsection.2.10.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.3.1}{What can go wrong with backpropagation ?}}{70}{subsubsection.2.10.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.4}{Regularizing neural networks and other practical considerations}}{71}{subsection.2.10.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.4.1}{Implicit regularization using SGD: Initialization, hyper-parameter tuning, and Early Stopping}}{72}{subsubsection.2.10.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.4.2}{Dropout}}{73}{subsubsection.2.10.4.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.10.4.3}{Batch Normalization}}{73}{subsubsection.2.10.4.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.5}{Deep neural networks in practice}}{74}{subsection.2.10.5}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.10.6}{Recipe DNNs}}{75}{subsection.2.10.6}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.11}{Convolutional Neural Networks (CNNS)}}{76}{section.2.11}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.11.1}{Symmetries}}{76}{subsection.2.11.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.11.2}{The structure of convolutional neural networks}}{77}{subsection.2.11.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.11.2.1}{Architecture}}{77}{subsubsection.2.11.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.11.2.2}{On convolutional layers}}{79}{subsubsection.2.11.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.11.2.3}{On pooling layers}}{79}{subsubsection.2.11.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.11.2.4}{Classifying layer}}{81}{subsubsection.2.11.2.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.11.3}{Pre-trained CNNs and transfer learning}}{82}{subsection.2.11.3}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {2.12}{High-Level Concepts in Deep Neural Networks}}{83}{section.2.12}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.12.1}{Organizing deep learning workflows using the bias-variance tradeoff}}{83}{subsection.2.12.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.12.2}{Why NN are so successful: three high-level perspectives on neural networks}}{85}{subsection.2.12.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.12.2.1}{Neural networks as representation learning}}{85}{subsubsection.2.12.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.12.2.2}{Neural networks can exploit large amounts of data}}{86}{subsubsection.2.12.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {2.12.2.3}{Neural networks scale up well computationally}}{86}{subsubsection.2.12.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {2.12.3}{Limitations of supervised learning with deep networks}}{86}{subsection.2.12.3}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {3}{Unsupervised Learning}}{89}{chapter.3}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.1}{Dimensional Reduction and Data Visualization}}{89}{section.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.1.1}{Some of the challenges of high-dimensional data}}{89}{subsection.3.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.1.1}{High-dimensional data lives near the edge of sample space}}{89}{subsubsection.3.1.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.1.2}{Real-world data vs. uniform distribution}}{89}{subsubsection.3.1.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.1.3}{Intrinsic dimensionality and the crowding problem}}{90}{subsubsection.3.1.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.1.2}{Principal component analysis (PCA)}}{91}{subsection.3.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.2.1}{The theory}}{91}{subsubsection.3.1.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.1.3}{Multidimensional scaling}}{92}{subsection.3.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.3.1}{Metric MDS}}{92}{subsubsection.3.1.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.3.2}{Non-metric MDS}}{92}{subsubsection.3.1.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.3.3}{General comment}}{92}{subsubsection.3.1.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.1.4}{t-SNE}}{93}{subsection.3.1.4}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.4.1}{The theory}}{93}{subsubsection.3.1.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.1.4.2}{Important properties of $t$-SNE}}{94}{subsubsection.3.1.4.2}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.2}{Clustering}}{95}{section.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.1}{Practical clustering methods}}{96}{subsection.3.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.1.1}{$K$-means}}{96}{subsubsection.3.2.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.1.2}{Hierarchical clustering: Agglomerative methods}}{97}{subsubsection.3.2.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.1.3}{Density-based (DB) clustering}}{99}{subsubsection.3.2.1.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.2}{Clustering and Latent Variables via the Gaussian Mixture Models}}{100}{subsection.3.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.2.1}{Important concepts in unsupervised learning}}{100}{subsubsection.3.2.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.2.2}{Concepts visualized via the Gaussian Mixture Model (GMM)}}{101}{subsubsection.3.2.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.2.3}{Clustering in high dimensions}}{103}{subsection.3.2.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.2.3.1}{Cluster validation in high dimensions}}{104}{subsubsection.3.2.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {3.3}{Variational Methods and Mean-Field Theory (MFT)}}{104}{section.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.3.1}{Variational methods introduction}}{104}{subsection.3.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.3.2}{Variational mean-field theory via Ising model}}{105}{subsection.3.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.3.2.1}{Important concepts of MFT}}{105}{subsubsection.3.3.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.3.2.2}{On the example of the Ising model}}{105}{subsubsection.3.3.2.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {3.3.3}{Expectation Maximization (EM)}}{106}{subsection.3.3.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.3.3.1}{EM in a nutshell - mathematical}}{107}{subsubsection.3.3.3.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsubsection}{\numberline {3.3.3.2}{EM via statistical physics}}{107}{subsubsection.3.3.3.2}
\defcounter {refsection}{0}\relax 
\contentsline {chapter}{\numberline {4}{Ideas for problems to work on}}{111}{chapter.4}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.1}{Physics problems}}{111}{section.4.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.1}{Cosmology}}{111}{subsection.4.1.1}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.1.2}{QFT}}{111}{subsection.4.1.2}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.2}{Ai safety}}{112}{section.4.2}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.2.1}{Questions}}{112}{subsection.4.2.1}
\defcounter {refsection}{0}\relax 
\contentsline {section}{\numberline {4.3}{Knobel-problems}}{112}{section.4.3}
\defcounter {refsection}{0}\relax 
\contentsline {subsection}{\numberline {4.3.1}{Ideas}}{112}{subsection.4.3.1}
